{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Acer\\\\Desktop\\\\lampix glass dettect\\\\models', 'C:\\\\Users\\\\Acer\\\\Desktop\\\\lampix glass dettect\\\\models\\\\research', 'C:\\\\Users\\\\Acer\\\\Desktop\\\\lampix glass dettect', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\python38.zip', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\Acer\\\\anaconda3', '', 'C:\\\\Users\\\\Acer\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Acer\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Acer\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'C:\\Users\\Acer\\Desktop\\lampix glass dettect\\models\\research')\n",
    "sys.path.insert(0, r'C:\\Users\\Acer\\Desktop\\lampix glass dettect\\models')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "#from object_detection.utils import colab_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import ntpath\n",
    "from pathlib import Path\n",
    "\n",
    "def aggregate_jsons(save_file = False):\n",
    "    res = {}\n",
    "    classes = {}\n",
    "    no_class = 0\n",
    "    for fn in glob.glob(r\"C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\*.json\"):\n",
    "        f = open(fn)\n",
    "        s = f.read()\n",
    "        o = json.loads(s)\n",
    "        deletes = []\n",
    "        for k in o:\n",
    "            print(k)\n",
    "            if len(o[k][\"regions\"]) == 0:\n",
    "                #print(fn, \" -> \", k)\n",
    "                deletes.append(k)\n",
    "            else:\n",
    "                for r in o[k][\"regions\"]:\n",
    "                    if \"Type\" in o[k][\"regions\"][r][\"region_attributes\"]:\n",
    "                        c = o[k][\"regions\"][r][\"region_attributes\"][\"Type\"].lower().strip()\n",
    "                        if c in classes:\n",
    "                            classes[c] += 1\n",
    "                        else:\n",
    "                            classes[c] = 1\n",
    "                    elif \"type\" in o[k][\"regions\"][r][\"region_attributes\"]:\n",
    "                        c = o[k][\"regions\"][r][\"region_attributes\"][\"type\"]\n",
    "                        if c in classes:\n",
    "                            classes[c] += 1\n",
    "                        else:\n",
    "                            classes[c] = 1                            \n",
    "                    else:\n",
    "                        no_class += 1\n",
    "\n",
    "        #print(len(deletes))\n",
    "        for k in deletes:\n",
    "            del o[k]\n",
    "            \n",
    "        res.update(o)\n",
    "        #if s.find(\"00084.jpg\") > 0:\n",
    "        #    # print(ntpath.basename(fn), \" for \", s)\n",
    "        #    sz = Path(\"/home/mihai/src/data/TDB_M-20201114T103840Z-001/TDB_M/00084.jpg\").stat().st_size\n",
    "        #    print(res[\"00084.jpg\" + str(sz)])\n",
    "        #    print(\"00084.jpg\" + str(sz))\n",
    "        #    break\n",
    "        f.close()\n",
    "\n",
    "    print(\"region classes:\", classes)\n",
    "    print(\"no class for\", no_class, \"regions\")\n",
    "    \n",
    "    if save_file:\n",
    "        f = open(\"bigjson.json\", \"w\")\n",
    "        f.write(json.dumps(res))\n",
    "        f.close()\n",
    "    return res, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_jsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region classes: {'glass': 4987, 'plate': 310, 'cup': 1115}\n",
      "no class for 15 regions\n",
      "no region data for  00002.jpg338727\n",
      "no region data for  00003.jpg301598\n",
      "no region data for  00004.jpg294643\n",
      "no region data for  00005.jpg299565\n",
      "no region data for  00006.jpg305176\n",
      "no region data for  00007.jpg301325\n",
      "no region data for  00008.jpg303852\n",
      "no region data for  00009.jpg287445\n",
      "no region data for  00010.jpg312631\n",
      "no region data for  00011.jpg328677\n",
      "no region data for  00012.jpg342041\n",
      "no region data for  00013.jpg342420\n",
      "no region data for  00014.jpg327238\n",
      "no region data for  00015.jpg338018\n",
      "no region data for  00016.jpg336979\n",
      "no region data for  00017.jpg344794\n",
      "no region data for  00018.jpg356870\n",
      "no region data for  00019.jpg365775\n",
      "no region data for  00020.jpg345683\n",
      "no region data for  00021.jpg341824\n",
      "no region data for  00022.jpg334768\n",
      "no region data for  00023.jpg315607\n",
      "no region data for  00024.jpg324922\n",
      "no region data for  00025.jpg312964\n",
      "no region data for  00026.jpg343717\n",
      "no region data for  00027.jpg281740\n",
      "no region data for  00028.jpg294184\n",
      "no region data for  00029.jpg326378\n",
      "no region data for  00030.jpg318492\n",
      "no region data for  00031.jpg290957\n",
      "no region data for  00032.jpg305763\n",
      "no region data for  00033.jpg336930\n",
      "no region data for  00034.jpg328064\n",
      "no region data for  00035.jpg332427\n",
      "no region data for  00036.jpg334673\n",
      "no region data for  00037.jpg330278\n",
      "no region data for  00038.jpg342544\n",
      "no region data for  00039.jpg307042\n",
      "no region data for  00040.jpg314711\n",
      "no region data for  00041.jpg293315\n",
      "no region data for  00042.jpg299656\n",
      "no region data for  00043.jpg298839\n",
      "no region data for  00044.jpg299188\n",
      "no region data for  00045.jpg276509\n",
      "no region data for  00046.jpg274062\n",
      "no region data for  00047.jpg311329\n",
      "no region data for  00048.jpg318393\n",
      "no region data for  00049.jpg323989\n",
      "no region data for  00050.jpg325713\n",
      "BAMMMM\n",
      "empty  49\n",
      "loaded  251\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import ntpath\n",
    "import cv2\n",
    "\n",
    "category_index = {}\n",
    "\n",
    "def load_data():\n",
    "    train_images_np = []\n",
    "    num = 0\n",
    "    num_empty = 0\n",
    "    data, classes = aggregate_jsons()\n",
    "    \n",
    "    label_id_offset = 1\n",
    "    train_image_tensors = []\n",
    "    gt_classes_one_hot_tensors = []\n",
    "    gt_box_tensors = []\n",
    "    category_by_name = {}\n",
    "    \n",
    "    n = 1\n",
    "    for c in classes:\n",
    "        category_index[n] = {'id': n, 'name': c}\n",
    "        category_by_name[c] = n\n",
    "        n += 1\n",
    "    \n",
    "    num_classes = len(classes)\n",
    "       \n",
    "    for fn in glob.glob(r\"C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\*.jpg\"):\n",
    "        sz = Path(fn).stat().st_size\n",
    "        # load the image\n",
    "        bname = ntpath.basename(fn)\n",
    "        k = bname + str(sz)\n",
    "        if k in data:\n",
    "            if len(data[k]['regions']) == 0:\n",
    "                print(bname, \": 0\")\n",
    "            else:\n",
    "                img = asarray(Image.open(fn))\n",
    "                res_y = img.shape[0]\n",
    "                res_x = img.shape[1]\n",
    "                boxes = []\n",
    "                classes = []\n",
    "                scores = []\n",
    "                for r in data[k]['regions']:\n",
    "                    ra = data[k]['regions'][r][\"region_attributes\"]\n",
    "                    if \"type\" in ra:\n",
    "                        cls = ra[\"type\"].lower().strip()\n",
    "                    elif \"Type\" in ra:\n",
    "                        cls = ra[\"Type\"].lower().strip()\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    rg = data[k]['regions'][r]['shape_attributes']\n",
    "                    npr = [rg['y']/res_y, rg['x']/res_x, (rg['y'] + rg['height'])/res_y, (rg['x'] + rg['width'])/res_x]\n",
    "                    boxes.append(npr)\n",
    "                    classes.append(category_by_name[cls])\n",
    "                    scores.append(1.0)\n",
    "                    break\n",
    "                    \n",
    "                if(len(boxes) >= 1):\n",
    "                    #print(\"classes are \", classes, \"and we have\", len(boxes), \"boxes\")\n",
    "                    train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(img, dtype=tf.float32), axis=0))\n",
    "                    gt_box_tensors.append(tf.convert_to_tensor(boxes, dtype=tf.float32))\n",
    "                    zero_indexed_groundtruth_classes = tf.convert_to_tensor(\n",
    "                       np.array(classes, dtype=np.int32) - label_id_offset)\n",
    "                    gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n",
    "                else:\n",
    "                    print(\"BAMMMM\")\n",
    "                \n",
    "                #ori_image = np.ones([360, 480, 3], dtype=np.int32) * 200\n",
    "                #test_image = img.copy()\n",
    "                #boxes = np.array(boxes, dtype=np.float32)\n",
    "                #classes = np.array(classes, dtype=np.int32)\n",
    "                #detections = np.ones(len(classes))\n",
    "                #i = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                #  test_image, boxes, classes, detections,\n",
    "                #  category_index,\n",
    "                #  use_normalized_coordinates=True,\n",
    "                #  min_score_thresh=0.3)\n",
    "                #cv2.imwrite(\"img.jpg\", i)\n",
    "        else:\n",
    "            print(\"no region data for \", k)\n",
    "            num_empty += 1\n",
    "\n",
    "        num += 1\n",
    "        \n",
    "        if num > 300: break\n",
    "            \n",
    "            \n",
    "    print(\"empty \", num_empty)\n",
    "    return train_image_tensors, gt_classes_one_hot_tensors, gt_box_tensors\n",
    "\n",
    "\n",
    "def show_some_data():\n",
    "    dummy_scores = np.array([1.0], dtype=np.float32)  # give boxes a score of 100%\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    for idx in range(5):\n",
    "      plt.subplot(2, 3, idx+1)\n",
    "      plot_detections(\n",
    "          train_images_np[idx],\n",
    "          gt_boxes[idx],\n",
    "          np.ones(shape=[gt_boxes[idx].shape[0]], dtype=np.int32),\n",
    "          dummy_scores, category_index)\n",
    "    plt.show()\n",
    "\n",
    "train_image_tensors, gt_classes_one_hot_tensors, gt_box_tensors = load_data()\n",
    "print(\"loaded \", len(train_image_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the checkpoint and put it into models/research/object_detection/test_data/\n",
    "\n",
    "# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "# !tar -xf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "# !if [ -d \"test_data/checkpoint\" ]; then rm -Rf test_data/checkpoint; fi\n",
    "# !mkdir test_data/checkpoint\n",
    "# !mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Building model and restoring weights for fine-tuning...\n",
      "INFO:tensorflow:Writing pipeline config file to C:\\Users\\Acer\\Desktop\\lampix glass dettect\\output\\pipeline.config\n",
      "WARNING:tensorflow:From C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1313: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n",
      "Weights restored!\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print('Building model and restoring weights for fine-tuning...', flush=True)\n",
    "num_classes = 3\n",
    "pipeline_config = r'C:\\Users\\Acer\\Desktop\\lampix glass dettect\\models\\research\\object_detection\\configs\\tf2\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'\n",
    "#pipeline_config = 'configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
    "#pipeline_config = 'configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
    "\n",
    "checkpoint_path = r'C:\\Users\\Acer\\Desktop\\lampix glass dettect\\models\\research\\object_detection\\test_data\\checkpoint\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\checkpoint\\ckpt-0.index'\n",
    "\n",
    "# This will be where we save checkpoint & config for TFLite conversion later.\n",
    "output_directory = r'C:\\Users\\Acer\\Desktop\\lampix glass dettect\\output'\n",
    "output_checkpoint_dir = os.path.join(output_directory, 'checkpoint')\n",
    "\n",
    "# Load pipeline config and build a detection model.\n",
    "#\n",
    "# Since we are working off of a COCO architecture which predicts 90\n",
    "# class slots by default, we override the `num_classes` field here to be just\n",
    "# one (for our new rubber ducky class).\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "model_config.ssd.num_classes = num_classes\n",
    "model_config.ssd.freeze_batchnorm = True\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=True)\n",
    "# Save new pipeline config\n",
    "pipeline_proto = config_util.create_pipeline_proto_from_configs(configs)\n",
    "config_util.save_pipeline_config(pipeline_proto, output_directory)\n",
    "\n",
    "# Set up object-based checkpoint restore --- SSD has two prediction\n",
    "# `heads` --- one for classification, the other for box regression.  We will\n",
    "# restore the box regression head but initialize the classification head\n",
    "# from scratch (we show the omission below by commenting out the line that\n",
    "# we would add if we wanted to restore both heads)\n",
    "fake_box_predictor = tf.compat.v2.train.Checkpoint(\n",
    "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
    "    # _prediction_heads=detection_model._box_predictor._prediction_heads,\n",
    "    #    (i.e., the classification head that we *will not* restore)\n",
    "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",
    "    )\n",
    "fake_model = tf.compat.v2.train.Checkpoint(\n",
    "          _feature_extractor=detection_model._feature_extractor,\n",
    "          _box_predictor=fake_box_predictor)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\n",
    "ckpt.restore(checkpoint_path).expect_partial()\n",
    "\n",
    "# To save checkpoint for TFLite conversion.\n",
    "exported_ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    exported_ckpt, output_checkpoint_dir, max_to_keep=1)\n",
    "\n",
    "# Run model through a dummy image so that variables are created\n",
    "image, shapes = detection_model.preprocess(tf.zeros([1, 320, 320, 3]))\n",
    "prediction_dict = detection_model.predict(image, shapes)\n",
    "_ = detection_model.postprocess(prediction_dict, shapes)\n",
    "print('Weights restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning!\n",
      "batch 0 of 300, loss=1.3804059\n",
      "batch 20 of 300, loss=1.3875898\n",
      "batch 40 of 300, loss=1.3767574\n",
      "batch 60 of 300, loss=1.3871756\n",
      "batch 80 of 300, loss=1.3677568\n",
      "batch 100 of 300, loss=1.3477806\n",
      "batch 120 of 300, loss=1.3843756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-160fb8389fc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;31m# Training step (forward pass + backwards pass)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m   \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_boxes_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_classes_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "# These parameters can be tuned; since our training set has 5 images\n",
    "# it doesn't make sense to have a much larger batch size, though we could\n",
    "# fit more examples in memory if we wanted to.\n",
    "batch_size = 25\n",
    "learning_rate = 1.0\n",
    "num_batches = 300\n",
    "\n",
    "# Select variables in top layers to fine-tune.\n",
    "trainable_variables = detection_model.trainable_variables\n",
    "to_fine_tune = []\n",
    "prefixes_to_train = [\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
    "for var in trainable_variables:\n",
    "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
    "    to_fine_tune.append(var)\n",
    "\n",
    "# Set up forward + backward pass for a single train step.\n",
    "def get_model_train_step_function(model, optimizer, vars_to_fine_tune):\n",
    "  \"\"\"Get a tf.function for training step.\"\"\"\n",
    "\n",
    "  # Use tf.function for a bit of speed.\n",
    "  # Comment out the tf.function decorator if you want the inside of the\n",
    "  # function to run eagerly.\n",
    "  @tf.function\n",
    "  def train_step_fn(image_tensors,\n",
    "                    groundtruth_boxes_list,\n",
    "                    groundtruth_classes_list):\n",
    "    \"\"\"A single training iteration.\n",
    "\n",
    "    Args:\n",
    "      image_tensors: A list of [1, height, width, 3] Tensor of type tf.float32.\n",
    "        Note that the height and width can vary across images, as they are\n",
    "        reshaped within this function to be 320x320.\n",
    "      groundtruth_boxes_list: A list of Tensors of shape [N_i, 4] with type\n",
    "        tf.float32 representing groundtruth boxes for each image in the batch.\n",
    "      groundtruth_classes_list: A list of Tensors of shape [N_i, num_classes]\n",
    "        with type tf.float32 representing groundtruth boxes for each image in\n",
    "        the batch.\n",
    "\n",
    "    Returns:\n",
    "      A scalar tensor representing the total loss for the input batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(\"img\", image_tensors[0].shape)\n",
    "    #print(\"boxes\", groundtruth_boxes_list[0].shape)\n",
    "    #print(\"classes\", groundtruth_classes_list[0])\n",
    "    \n",
    "    shapes = tf.constant(batch_size * [[320, 320, 3]], dtype=tf.int32)\n",
    "    model.provide_groundtruth(\n",
    "        groundtruth_boxes_list=groundtruth_boxes_list,\n",
    "        groundtruth_classes_list=groundtruth_classes_list)\n",
    "    with tf.GradientTape() as tape:\n",
    "      preprocessed_images = tf.concat(\n",
    "          [detection_model.preprocess(image_tensor)[0]\n",
    "           for image_tensor in image_tensors], axis=0)\n",
    "      prediction_dict = model.predict(preprocessed_images, shapes)\n",
    "      losses_dict = model.loss(prediction_dict, shapes)\n",
    "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
    "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
    "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
    "    return total_loss\n",
    "\n",
    "  return train_step_fn\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.5)\n",
    "train_step_fn = get_model_train_step_function(\n",
    "    detection_model, optimizer, to_fine_tune)\n",
    "\n",
    "print('Start fine-tuning!', flush=True)\n",
    "for idx in range(num_batches):\n",
    "  # Grab keys for a random subset of examples\n",
    "  all_keys = list(range(len(train_image_tensors)))\n",
    "  random.shuffle(all_keys)\n",
    "  example_keys = all_keys[:batch_size]\n",
    "\n",
    "  # Note that we do not do data augmentation in this demo.  If you want a\n",
    "  # a fun exercise, we recommend experimenting with random horizontal flipping\n",
    "  # and random cropping :)\n",
    "  gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\n",
    "  gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\n",
    "  image_tensors = [train_image_tensors[key] for key in example_keys]\n",
    "\n",
    "  # Training step (forward pass + backwards pass)\n",
    "  total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)\n",
    "\n",
    "  if idx % 20 == 0:\n",
    "    print('batch ' + str(idx) + ' of ' + str(num_batches)\n",
    "    + ', loss=' +  str(total_loss.numpy()), flush=True)\n",
    "\n",
    "print('Done fine-tuning!')\n",
    "ckpt_manager.save()\n",
    "\n",
    "print('Checkpoint saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00014.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n",
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00025.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00058.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n",
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00025.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00091.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n",
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00005.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00007.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n",
      "C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\00010.jpg\n",
      "[[0.         0.         0.11326203 0.07320088]\n",
      " [0.         0.00107234 0.11326203 0.12320088]\n",
      " [0.         0.05107234 0.11326203 0.17320089]\n",
      " [0.         0.10107234 0.11326203 0.22320089]\n",
      " [0.         0.15107234 0.11326203 0.2732009 ]\n",
      " [0.         0.20107234 0.11326203 0.32320088]\n",
      " [0.         0.25107235 0.11326203 0.3732009 ]\n",
      " [0.         0.30107236 0.11326203 0.4232009 ]\n",
      " [0.         0.35107237 0.11326203 0.47320092]\n",
      " [0.         0.40107232 0.11326203 0.52320087]\n",
      " [0.         0.4510723  0.11326203 0.5732008 ]\n",
      " [0.         0.5010723  0.11326203 0.6232009 ]\n",
      " [0.         0.5510723  0.11326203 0.6732009 ]\n",
      " [0.         0.6010723  0.11326203 0.7232009 ]\n",
      " [0.         0.6510723  0.11326203 0.7732008 ]\n",
      " [0.         0.7010724  0.11326203 0.8232009 ]\n",
      " [0.         0.7510723  0.11326203 0.8732009 ]\n",
      " [0.         0.8010723  0.11326203 0.9232009 ]\n",
      " [0.         0.8510723  0.11326203 0.9732009 ]\n",
      " [0.         0.9010723  0.11326203 1.        ]\n",
      " [0.         0.         0.13826203 0.09820088]\n",
      " [0.         0.02607235 0.13826203 0.14820088]\n",
      " [0.         0.07607234 0.13826203 0.19820088]\n",
      " [0.         0.12607233 0.13826203 0.24820088]\n",
      " [0.         0.17607233 0.13826203 0.29820088]\n",
      " [0.         0.22607234 0.13826203 0.3482009 ]\n",
      " [0.         0.27607232 0.13826203 0.39820093]\n",
      " [0.         0.32607234 0.13826203 0.44820088]\n",
      " [0.         0.37607235 0.13826203 0.4982009 ]\n",
      " [0.         0.42607236 0.13826203 0.5482009 ]\n",
      " [0.         0.4760723  0.13826203 0.5982009 ]\n",
      " [0.         0.5260723  0.13826203 0.6482008 ]\n",
      " [0.         0.5760724  0.13826203 0.6982009 ]\n",
      " [0.         0.6260723  0.13826203 0.7482009 ]\n",
      " [0.         0.6760723  0.13826203 0.7982009 ]\n",
      " [0.         0.7260723  0.13826203 0.8482009 ]\n",
      " [0.         0.7760723  0.13826203 0.8982008 ]\n",
      " [0.         0.8260724  0.13826203 0.9482009 ]\n",
      " [0.         0.8760723  0.13826203 0.9982009 ]\n",
      " [0.         0.9260723  0.13826203 1.        ]\n",
      " [0.         0.         0.18826203 0.07320088]\n",
      " [0.         0.00107234 0.18826203 0.12320088]\n",
      " [0.         0.05107234 0.18826203 0.17320089]\n",
      " [0.         0.10107234 0.18826203 0.22320089]\n",
      " [0.         0.15107234 0.18826203 0.2732009 ]\n",
      " [0.         0.20107234 0.18826203 0.32320088]\n",
      " [0.         0.25107235 0.18826203 0.3732009 ]\n",
      " [0.         0.30107236 0.18826203 0.4232009 ]\n",
      " [0.         0.35107237 0.18826203 0.47320092]\n",
      " [0.         0.40107232 0.18826203 0.52320087]\n",
      " [0.         0.4510723  0.18826203 0.5732008 ]\n",
      " [0.         0.5010723  0.18826203 0.6232009 ]\n",
      " [0.         0.5510723  0.18826203 0.6732009 ]\n",
      " [0.         0.6010723  0.18826203 0.7232009 ]\n",
      " [0.         0.6510723  0.18826203 0.7732008 ]\n",
      " [0.         0.7010724  0.18826203 0.8232009 ]\n",
      " [0.         0.7510723  0.18826203 0.8732009 ]\n",
      " [0.         0.8010723  0.18826203 0.9232009 ]\n",
      " [0.         0.8510723  0.18826203 0.9732009 ]\n",
      " [0.         0.9010723  0.18826203 1.        ]\n",
      " [0.01202443 0.         0.21326204 0.09820088]\n",
      " [0.01202443 0.02607235 0.21326204 0.14820088]\n",
      " [0.01202443 0.07607234 0.21326204 0.19820088]\n",
      " [0.01202443 0.12607233 0.21326204 0.24820088]\n",
      " [0.01202443 0.17607233 0.21326204 0.29820088]\n",
      " [0.01202443 0.22607234 0.21326204 0.3482009 ]\n",
      " [0.01202443 0.27607232 0.21326204 0.39820093]\n",
      " [0.01202443 0.32607234 0.21326204 0.44820088]\n",
      " [0.01202443 0.37607235 0.21326204 0.4982009 ]\n",
      " [0.01202443 0.42607236 0.21326204 0.5482009 ]\n",
      " [0.01202443 0.4760723  0.21326204 0.5982009 ]\n",
      " [0.01202443 0.5260723  0.21326204 0.6482008 ]\n",
      " [0.01202443 0.5760724  0.21326204 0.6982009 ]\n",
      " [0.01202443 0.6260723  0.21326204 0.7482009 ]\n",
      " [0.01202443 0.6760723  0.21326204 0.7982009 ]\n",
      " [0.01202443 0.7260723  0.21326204 0.8482009 ]\n",
      " [0.01202443 0.7760723  0.21326204 0.8982008 ]\n",
      " [0.01202443 0.8260724  0.21326204 0.9482009 ]\n",
      " [0.01202443 0.8760723  0.21326204 0.9982009 ]\n",
      " [0.01202443 0.9260723  0.21326204 1.        ]\n",
      " [0.06202443 0.         0.26326203 0.07320088]\n",
      " [0.06202443 0.00107234 0.26326203 0.12320088]\n",
      " [0.06202443 0.05107234 0.26326203 0.17320089]\n",
      " [0.06202443 0.10107234 0.26326203 0.22320089]\n",
      " [0.06202443 0.15107234 0.26326203 0.2732009 ]\n",
      " [0.06202443 0.20107234 0.26326203 0.32320088]\n",
      " [0.06202443 0.25107235 0.26326203 0.3732009 ]\n",
      " [0.06202443 0.30107236 0.26326203 0.4232009 ]\n",
      " [0.06202443 0.35107237 0.26326203 0.47320092]\n",
      " [0.06202443 0.40107232 0.26326203 0.52320087]\n",
      " [0.06202443 0.4510723  0.26326203 0.5732008 ]\n",
      " [0.06202443 0.5010723  0.26326203 0.6232009 ]\n",
      " [0.06202443 0.5510723  0.26326203 0.6732009 ]\n",
      " [0.06202443 0.6010723  0.26326203 0.7232009 ]\n",
      " [0.06202443 0.6510723  0.26326203 0.7732008 ]\n",
      " [0.06202443 0.7010724  0.26326203 0.8232009 ]\n",
      " [0.06202443 0.7510723  0.26326203 0.8732009 ]\n",
      " [0.06202443 0.8010723  0.26326203 0.9232009 ]\n",
      " [0.06202443 0.8510723  0.26326203 0.9732009 ]\n",
      " [0.06202443 0.9010723  0.26326203 1.        ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.] [0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755 0.05202755\n",
      " 0.05202755 0.05202755 0.05202755 0.05202755]\n"
     ]
    }
   ],
   "source": [
    "images = [12, 23, 56, 23, 89, 3, 5, 8]\n",
    "num_predictions = len(images)\n",
    "image_tensors = []\n",
    "\n",
    "img_files = glob.glob(r\"C:\\Users\\Acer\\Desktop\\lampix glass dettect\\TDB_M\\*.jpg\")\n",
    "\n",
    "for i in images:\n",
    "    print(img_files[i])\n",
    "    img = asarray(Image.open(img_files[i]))\n",
    "    image_tensors = []\n",
    "    image_tensors.append(tf.expand_dims(tf.convert_to_tensor(img, dtype=tf.float32), axis=0))\n",
    "\n",
    "    #preprocessed_images = tf.concat(\n",
    "    #  [detection_model.preprocess(image_tensor)[0] for image_tensor in image_tensors], axis=0)\n",
    "    #shapes = tf.constant(num_predictions * [[320, 320, 3]], dtype=tf.int32)\n",
    "\n",
    "    preprocessed_images, shapes = detection_model.preprocess(image_tensors[0])\n",
    "\n",
    "    prediction_dict = detection_model.predict(preprocessed_images, shapes)\n",
    "\n",
    "    result = detection_model.postprocess(prediction_dict, None)\n",
    "\n",
    "    boxes = result[\"detection_boxes\"]\n",
    "    classes = result[\"detection_classes\"]\n",
    "    scores = result[\"detection_scores\"]\n",
    "\n",
    "    print(boxes[0].numpy(), classes[0].numpy(), scores[0].numpy())\n",
    "\n",
    "    #ori_image = np.ones([360, 480, 3], dtype=np.int32) * 200\n",
    "    #test_image = img.copy()\n",
    "    #boxes = np.array(boxes, dtype=np.float32)\n",
    "    #classes = np.array(classes, dtype=np.int32)\n",
    "    #detections = np.ones(len(classes))\n",
    "    test_image = img.copy()\n",
    "    im = viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      test_image, boxes[0].numpy(), (classes[0].numpy() + 1).astype(int), scores[0].numpy(),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.01)\n",
    "    cv2.imwrite(\"img%d.jpg\" % i, im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0].numpy() > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1195f01e3cbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"img%d.jpg\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"img%d.jpg\" % 100, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
